# Data Pipeline Python, Google Cloud Platform, and Google Data Studio
1. Data Collection and Cleansing with Python from MySQL and REST API.
2. Extracted the data into Landing zone with Google Cloud Storage.
3. Transform data using Apache Spark and loaded into Google BigQuery.
4. Visualisation with Google Data Studio
5. The pipeline is orchestrated using Airflow with Cloud Composer (GCP).

# Visualisation with Google Data Studio
A view was created to illustrated the neccesary data: revenue, country, book name, customer id, category, purchased date, book id.

The first dashboard illustrated the overview which included the revenue of the business, no. of customer, transaction by country, besting selling book, and best selling categories.
<img width="1197" alt="Screen Shot 2565-01-18 at 18 01 31" src="https://user-images.githubusercontent.com/73461649/149925506-800b75f7-5d3d-4055-9fcd-f737789e4ac7.png">

The second dashboard illustrated "search book by revenue". It consists of a user defined parameter that will match result with the search criteria. 
<img width="1198" alt="Screen Shot 2565-01-18 at 18 01 37" src="https://user-images.githubusercontent.com/73461649/149925510-3902aed4-4163-4986-92fe-9d9dcaad18cd.png">
<img width="1195" alt="Screen Shot 2565-01-18 at 18 01 46" src="https://user-images.githubusercontent.com/73461649/149925515-9e3bd2b4-8bcc-4c1e-8833-aa24a81d100c.png">
